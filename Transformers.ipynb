{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lihkLXYnssX"
      },
      "source": [
        "**Transformers:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnQObIBxn26_"
      },
      "source": [
        "\n",
        "\n",
        "*   Transformers are a type of neural network architecture that relies on attention mechanism. The attention mechanism helps the model to learn long-range dependencies between different parts of a sequence.\n",
        "\n",
        "*   Transformer is composed of two parts: Encoder and decoder. Encoder takes the input sequence and produces hidden states, and the decoder takes the hidden states and produces output sequence.\n",
        "\n",
        "*   Transformers are now used for variety of natural language processing tasks including machine translation, text summarization and question answering. They have been used for other tasks such as speech recognition and computer vision.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tm-7pHLbFGMk"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvTJ9zQXcCbE"
      },
      "source": [
        "#Encoder Part: Text classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "xmUyossccH6I"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "kdfTV7AecRiu"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Y-UdtWdwcUMC"
      },
      "outputs": [],
      "source": [
        "!pip install bertviz\n",
        "!pip install umap-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zmzBH4MUdwxG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "zW18O4RnoamF"
      },
      "outputs": [],
      "source": [
        "dataset=load_dataset(\"dair-ai/emotion\")\n",
        "dataset.set_format(type=\"pandas\") #setting the dataset as pandas dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7VLibj1Npxcm"
      },
      "outputs": [],
      "source": [
        "df = dataset['train'][:] #the dataset will be displayed in pandas format\n",
        "df.head() #shows first 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3I9ykQBuqfM9"
      },
      "outputs": [],
      "source": [
        "classes = dataset['train'].features['label'].names #trying to get the label names as shown in huggingface\n",
        "classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eDYv6HsfrBf5"
      },
      "outputs": [],
      "source": [
        "df['label_name'] = df['label'].apply(lambda x: classes[x]) #apply showing label names for each label\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0afEwu1LFEYI"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pt1W91R3rn3T"
      },
      "source": [
        "#Dataset Analysis\n",
        "<br>\n",
        "Dataset analysis is required to undestand more about our dataset and class distribution and overall data distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAI6DsvosIB0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "label_counts =df['label_name'].value_counts(ascending=True)\n",
        "label_counts.plot.barh()\n",
        "plt.title('Frequency of Classes')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GK_UTD82ZA3"
      },
      "outputs": [],
      "source": [
        "df['Words Per Tweet'] = df['text'].str.split().apply(len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSX3dPWR3jEd"
      },
      "outputs": [],
      "source": [
        "df.boxplot(\"Words Per Tweet\", by='label_name')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIg2ajQxFCgP"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhg1JGka4VA4"
      },
      "source": [
        "#Text to Token Conversion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "q8VkjueM42o7"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer #This will automatically fetch the tokenization technique based on the model name\n",
        "model_ckpt = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoS07PCL6iS5"
      },
      "outputs": [],
      "source": [
        "text = \"Valentine's day. Crying in the hotel bar.\"\n",
        "encoded_text = tokenizer(text)\n",
        "print(encoded_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhKfW0cy7XN4"
      },
      "source": [
        "You find 101 and 102 in the list. These are special tokens. 101 marks the start of a sentence (CLS), 102 marks the end of the sentence (separator)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iId-pVCA9RcT"
      },
      "outputs": [],
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jHY2YYK-IMG"
      },
      "source": [
        "The uppercase in the sentence have been turned to lower case because we are using DistilBERT uncased model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cuA77NNhvYOr"
      },
      "outputs": [],
      "source": [
        "tokenizer.vocab_size, tokenizer.model_max_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvGsaOjCvYl-"
      },
      "source": [
        "This displays the total no. of tokens in the dictionary and maximum sequence length of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fJ9d76HFAqy"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q9cM3nMp-phI"
      },
      "source": [
        "#Tokenization of the Emotion Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5k7G5we-qsN"
      },
      "outputs": [],
      "source": [
        "dataset.reset_format() #To work on the whole data in one go."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFyoHh29u7_U"
      },
      "outputs": [],
      "source": [
        "#map - tokenization method\n",
        "def tokenize(batch):\n",
        "  temp = tokenizer(batch['text'], padding=True, truncation=True) #takes a batch of data and applies padding - so all are in same length, truncation - so sequences longer than max length for model are truncated\n",
        "  return temp\n",
        "\n",
        "print(tokenize(dataset[\"train\"][:2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Scs9m1DaBoLs"
      },
      "source": [
        "The result is token IDs of each word (tokenized) and attention mask to show which of them are padding and which is actual data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BodlkzbwD5PO"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Ob1bUbgD7B6"
      },
      "source": [
        "Here we are encoding the dataset. \"batched=True, batch_size=None\" would mean at one go, train split will pass as a whole data and test split as a whole data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sDu326kCASg"
      },
      "outputs": [],
      "source": [
        "dataset_encoded = dataset.map(tokenize, batched=True, batch_size=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ipOQ7YzlEroW"
      },
      "outputs": [],
      "source": [
        "dataset_encoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ri6WJKYYFKJz"
      },
      "source": [
        "<br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kNH37SZE8-r"
      },
      "source": [
        "#Model Building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6OdqWEHE-nE"
      },
      "outputs": [],
      "source": [
        "text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKp7fPcPFqPf"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(text, return_tensors='pt')\n",
        "inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bspIQZsGast"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModel\n",
        "import torch\n",
        "\n",
        "model = AutoModel.from_pretrained(model_ckpt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TPGE2e0OG2gK"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLCVRIifHEM0"
      },
      "source": [
        "The model has multiple layers. Firstly, we find embedding layer that generate embeddings. Then there's transformer that has encoder stack and uses multi-head self attention technique."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skj3V9qB8hks"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "last_hidden_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14WX6Kzv-dlF"
      },
      "outputs": [],
      "source": [
        "last_hidden_states.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qSZ2mM0-qLh"
      },
      "source": [
        "768 - total length of vector generated by DistilBERT\n",
        "<br>13 - No. of tokens present in the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPG1ckVaAB9X"
      },
      "source": [
        "*   AutoModelForSequenceClassification model has a classification head on top of the pretrained model outputs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6queR7RfAevc"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") #Checks if GPU is available and uses it, if not then uses CPU.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_ckpt, num_labels=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sK4bPIxmBjWB"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "batch_size = 64\n",
        "model_name = \"distilbert-finetuned-emotion-recog\"\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=model_name,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy='epoch',\n",
        "    disable_tqdm=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vL5IA4P3EitE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average='weighted')\n",
        "  acc = accuracy_score(labels, preds)\n",
        "  return {'accuracy': acc, 'f1': f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNc16CesFXCb"
      },
      "outputs": [],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    compute_metrics=compute_metrics,\n",
        "    train_dataset=dataset_encoded[\"train\"],\n",
        "    eval_dataset=dataset_encoded[\"validation\"],\n",
        "    processing_class=tokenizer  # Changed from tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwEz77WMLkyh"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds_outputs = trainer.predict(dataset_encoded['test'])\n",
        "preds_outputs.metrics"
      ],
      "metadata": {
        "id": "lD0MMYfGW6iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_preds = np.argmax(preds_outputs.predictions, axis=1)\n",
        "y_true = dataset_encoded['test'][:]['label']"
      ],
      "metadata": {
        "id": "Od9rOIOmZRNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classes)\n",
        "print(classification_report(y_true, y_preds))"
      ],
      "metadata": {
        "id": "IqG9LxriZyPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_counts"
      ],
      "metadata": {
        "id": "zEtnFRGoaF2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing for the prediction"
      ],
      "metadata": {
        "id": "icrDqGl7ahlw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"I feel alone even when I have a crowd around me.\"\n",
        "dataset_encoded = tokenizer(text, return_tensors='pt').to(device)\n",
        "with torch.no_grad():\n",
        "    outputs = model(**dataset_encoded)\n",
        "logits = outputs.logits\n",
        "pred = torch.argmax(logits, dim=1)\n",
        "pred, classes[pred]"
      ],
      "metadata": {
        "id": "t00gu3zTanz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "outputs"
      ],
      "metadata": {
        "id": "cb_Tcah_bgfI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}